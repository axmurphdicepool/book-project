{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ID = \"book-project-479914\"   # <-- your project\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "df = client.query(\"\"\"\n",
    "    SELECT *\n",
    "    FROM `book-project-479914.harmonized_data.maybe_final_concat`\n",
    "\"\"\").to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rapidfuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af829c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from rapidfuzz import fuzz, process\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 0. CLEAN NUMERIC / BOOLEAN COLUMNS\n",
    "# ----------------------------------------------------\n",
    "for col in ['awards', 'bestseller', 'classic']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. CLEAN TITLE AND AUTHOR\n",
    "# ----------------------------------------------------\n",
    "def normalize_text(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^a-z0-9 ]+', '', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "df['title_clean'] = df['title'].apply(normalize_text)\n",
    "df['author_clean'] = df['author'].apply(normalize_text)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. BLOCKING: reduce comparisons\n",
    "# ----------------------------------------------------\n",
    "df['block'] = df['title_clean'].str[:5] + df['author_clean'].str[:3]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. FUZZY CLUSTERING\n",
    "# ----------------------------------------------------\n",
    "cluster_id = 0\n",
    "cluster_map = {}  # row index -> cluster id\n",
    "assigned = set()\n",
    "\n",
    "for block_val, group in tqdm(df.groupby('block'), desc=\"Processing blocks\"):\n",
    "    indices = group.index.tolist()\n",
    "    titles = list(group['title_clean'])\n",
    "    authors = list(group['author_clean'])\n",
    "    \n",
    "    while indices:\n",
    "        idx0 = indices.pop(0)\n",
    "        title0 = titles[group.index.get_loc(idx0)]\n",
    "        author0 = authors[group.index.get_loc(idx0)]\n",
    "\n",
    "        candidates = [i for i in indices if i not in assigned]\n",
    "        if not candidates:\n",
    "            cluster_map[idx0] = cluster_id\n",
    "            cluster_id += 1\n",
    "            continue\n",
    "\n",
    "        candidate_titles = [df.at[i, 'title_clean'] for i in candidates]\n",
    "        candidate_authors = [df.at[i, 'author_clean'] for i in candidates]\n",
    "\n",
    "        title_scores = process.cdist([title0], candidate_titles, scorer=fuzz.token_sort_ratio)[0]\n",
    "        author_scores = process.cdist([author0], candidate_authors, scorer=fuzz.token_sort_ratio)[0]\n",
    "\n",
    "        matched_indices = [candidates[i] for i, (ts, as_) in enumerate(zip(title_scores, author_scores)) if ts >= 75 and as_ >= 75]\n",
    "\n",
    "        # assign cluster\n",
    "        cluster_map[idx0] = cluster_id\n",
    "        for m in matched_indices:\n",
    "            cluster_map[m] = cluster_id\n",
    "            assigned.add(m)\n",
    "            indices.remove(m)\n",
    "\n",
    "        assigned.add(idx0)\n",
    "        cluster_id += 1\n",
    "\n",
    "df['cluster_id'] = df.index.map(cluster_map)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. AGGREGATE CLUSTERS (VECTORIZE WITH AGG)\n",
    "# ----------------------------------------------------\n",
    "agg_funcs = {\n",
    "    'source': pd.Series.nunique,\n",
    "    'title': 'first',\n",
    "    'author': 'first',\n",
    "    'review': 'mean',\n",
    "    'reviews_count': 'sum',\n",
    "    'published_year': 'min',\n",
    "    'price_eur': 'mean',\n",
    "    'length': lambda x: x.value_counts().idxmax() if not x.value_counts().empty else None,\n",
    "    'awards': 'max',\n",
    "    'bestseller': 'max',\n",
    "    'classic': 'max',\n",
    "    'book_series': lambda x: 1 if x.notna().any() else 0,\n",
    "    'genre': lambda x: \", \".join(x.dropna().unique()) if x.notna().any() else None,\n",
    "    'years_on_bestsellers_list': 'sum'\n",
    "}\n",
    "\n",
    "df_final = df.groupby('cluster_id').agg(agg_funcs).reset_index()\n",
    "df_final['price_eur'] = df_final['price_eur'].round(2)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. FINAL OUTPUT\n",
    "# ----------------------------------------------------\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f51ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('deduplicated.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
